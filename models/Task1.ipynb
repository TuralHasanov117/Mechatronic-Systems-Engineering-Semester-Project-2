{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1**"
      ],
      "metadata": {
        "id": "Dh4hdMgK5JRm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8FiJx9BJ0DB4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import glob\n",
        "import PIL.Image\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_NRwQMJa3nB",
        "outputId": "2ffe8139-fe75-46d1-dcc5-01cb030a302b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/dataset/apex'"
      ],
      "metadata": {
        "id": "is0Bc9Uh3RDX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction"
      ],
      "metadata": {
        "id": "lYqULAgz5WlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_x(path, width):\n",
        "    \"Gets the x value from the image filename\"\n",
        "    return (float(int(path.split(\"_\")[0])) - width / 2) / (width / 2)\n",
        "\n",
        "\n",
        "def get_y(path, height):\n",
        "    \"Gets the y value from the image filename\"\n",
        "    return (float(int(path.split(\"_\")[1])) - height / 2) / (height / 2)"
      ],
      "metadata": {
        "id": "ehCxThtp5W7P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "1daLh7yCYhpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class XYDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, directory, random_hflips=False):\n",
        "        self.directory = directory\n",
        "        self.random_hflips = random_hflips\n",
        "        self.image_paths = glob.glob(os.path.join(self.directory, '*.jpg'))\n",
        "        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "\n",
        "        image = PIL.Image.open(image_path)\n",
        "        width, height = image.size\n",
        "        x = float(get_x(os.path.basename(image_path), width))\n",
        "        y = float(get_y(os.path.basename(image_path), height))\n",
        "\n",
        "        if float(np.random.rand(1)) > 0.5:\n",
        "            image = transforms.functional.hflip(image)\n",
        "            x = -x\n",
        "\n",
        "        image = self.color_jitter(image)\n",
        "        image = transforms.functional.resize(image, (224, 224))\n",
        "        image = transforms.functional.to_tensor(image)\n",
        "        image = image.numpy()[::-1].copy()\n",
        "        image = torch.from_numpy(image)\n",
        "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "\n",
        "        return image, torch.tensor([x, y]).float()"
      ],
      "metadata": {
        "id": "EFORIffLYhPU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test Split"
      ],
      "metadata": {
        "id": "u1RDmwHAGNK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = XYDataset(data_path, random_hflips=False)\n",
        "\n",
        "\n",
        "test_percent = 0.1\n",
        "num_test = int(test_percent * len(dataset))\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])"
      ],
      "metadata": {
        "id": "I7B3WyNz5h3A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "JrbyYJiTGMlP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Base Model"
      ],
      "metadata": {
        "id": "vq7iyoJu5Shc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(weights='ResNet18_Weights.DEFAULT')"
      ],
      "metadata": {
        "id": "TCxtDwUQ1XVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37331da1-ce97-4c0c-9713-4b8e88f8d220"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 114MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = torch.nn.Linear(512, 2)\n",
        "device = torch.device('cuda')\n",
        "model = model.to(device)\n",
        "\n",
        "NUM_EPOCHS = 50\n",
        "BEST_MODEL_PATH = '/best_steering_model_xy.pth'\n",
        "best_loss = 1e9"
      ],
      "metadata": {
        "id": "HqVRjIyHGfi0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in iter(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = F.mse_loss(outputs, labels)\n",
        "        train_loss += float(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    model.eval().to(device)\n",
        "    test_loss = 0.0\n",
        "    for images, labels in iter(test_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = F.mse_loss(outputs, labels)\n",
        "        test_loss += float(loss)\n",
        "    test_loss /= len(test_loader)\n",
        "\n",
        "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}')\n",
        "    if test_loss < best_loss:\n",
        "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "        best_loss = test_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQyIcTn7J6J0",
        "outputId": "78eab088-2e9b-48a4-a4d1-f325a0bd12f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-926b25b0c33b>:20: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  if float(np.random.rand(1)) > 0.5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train Loss: 0.090614, Test Loss: 0.124570\n",
            "Epoch: 2, Train Loss: 0.063452, Test Loss: 0.046816\n",
            "Epoch: 3, Train Loss: 0.060435, Test Loss: 0.044821\n",
            "Epoch: 4, Train Loss: 0.054387, Test Loss: 0.047325\n",
            "Epoch: 5, Train Loss: 0.050689, Test Loss: 0.022985\n",
            "Epoch: 6, Train Loss: 0.047439, Test Loss: 0.019307\n",
            "Epoch: 7, Train Loss: 0.052934, Test Loss: 0.049293\n",
            "Epoch: 8, Train Loss: 0.043158, Test Loss: 0.040233\n",
            "Epoch: 9, Train Loss: 0.045555, Test Loss: 0.028758\n",
            "Epoch: 10, Train Loss: 0.040277, Test Loss: 0.070047\n",
            "Epoch: 11, Train Loss: 0.041903, Test Loss: 0.073603\n",
            "Epoch: 12, Train Loss: 0.037127, Test Loss: 0.027684\n",
            "Epoch: 13, Train Loss: 0.032783, Test Loss: 0.050832\n",
            "Epoch: 14, Train Loss: 0.032636, Test Loss: 0.048398\n",
            "Epoch: 15, Train Loss: 0.031210, Test Loss: 0.025205\n",
            "Epoch: 16, Train Loss: 0.029074, Test Loss: 0.016974\n",
            "Epoch: 17, Train Loss: 0.023225, Test Loss: 0.020892\n",
            "Epoch: 18, Train Loss: 0.031718, Test Loss: 0.017106\n",
            "Epoch: 19, Train Loss: 0.024615, Test Loss: 0.017229\n",
            "Epoch: 20, Train Loss: 0.026292, Test Loss: 0.021297\n",
            "Epoch: 21, Train Loss: 0.025083, Test Loss: 0.016550\n",
            "Epoch: 22, Train Loss: 0.019281, Test Loss: 0.041333\n",
            "Epoch: 23, Train Loss: 0.019218, Test Loss: 0.025626\n",
            "Epoch: 24, Train Loss: 0.019468, Test Loss: 0.025320\n",
            "Epoch: 25, Train Loss: 0.017259, Test Loss: 0.020321\n",
            "Epoch: 26, Train Loss: 0.017417, Test Loss: 0.019951\n",
            "Epoch: 27, Train Loss: 0.014745, Test Loss: 0.015411\n",
            "Epoch: 28, Train Loss: 0.015127, Test Loss: 0.012490\n",
            "Epoch: 29, Train Loss: 0.013491, Test Loss: 0.016730\n",
            "Epoch: 30, Train Loss: 0.016880, Test Loss: 0.011939\n",
            "Epoch: 31, Train Loss: 0.014104, Test Loss: 0.015160\n",
            "Epoch: 32, Train Loss: 0.012781, Test Loss: 0.013451\n",
            "Epoch: 33, Train Loss: 0.014303, Test Loss: 0.036254\n",
            "Epoch: 34, Train Loss: 0.014966, Test Loss: 0.019609\n",
            "Epoch: 35, Train Loss: 0.014611, Test Loss: 0.015997\n",
            "Epoch: 36, Train Loss: 0.013107, Test Loss: 0.031566\n",
            "Epoch: 37, Train Loss: 0.013469, Test Loss: 0.015322\n",
            "Epoch: 38, Train Loss: 0.012224, Test Loss: 0.016868\n",
            "Epoch: 39, Train Loss: 0.012450, Test Loss: 0.014494\n",
            "Epoch: 40, Train Loss: 0.013775, Test Loss: 0.027313\n",
            "Epoch: 41, Train Loss: 0.013095, Test Loss: 0.014379\n",
            "Epoch: 42, Train Loss: 0.012027, Test Loss: 0.012239\n",
            "Epoch: 43, Train Loss: 0.011477, Test Loss: 0.016073\n",
            "Epoch: 44, Train Loss: 0.011914, Test Loss: 0.019342\n",
            "Epoch: 45, Train Loss: 0.011504, Test Loss: 0.012580\n",
            "Epoch: 46, Train Loss: 0.012739, Test Loss: 0.012458\n",
            "Epoch: 47, Train Loss: 0.011974, Test Loss: 0.023560\n",
            "Epoch: 48, Train Loss: 0.011125, Test Loss: 0.012179\n",
            "Epoch: 49, Train Loss: 0.010261, Test Loss: 0.009222\n",
            "Epoch: 50, Train Loss: 0.011003, Test Loss: 0.011068\n"
          ]
        }
      ]
    }
  ]
}